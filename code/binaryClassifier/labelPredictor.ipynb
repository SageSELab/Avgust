{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca04130",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from binaryClassifier import Net\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840dfb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=89888, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=2, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['typing','noTyping']\n",
    "\n",
    "model = Net()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = torch.load('/Users/XXX/Desktop/model_cifar.pt')\n",
    "# checkpoint.eval()\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488ec4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test'\n",
    "test_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "                                     ])\n",
    " \n",
    "\n",
    "\n",
    "def predict_image(image):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3902b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "# instantiate the dataset and dataloader\n",
    "data_dir = '/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test'\n",
    "dataset = ImageFolderWithPaths(data_dir,transform=test_transforms) # our custom dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002fe078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/0.jpg',) : predicted : noTyping\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/1.jpg',) : predicted : noTyping\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/2.jpg',) : predicted : noTyping\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/3.jpg',) : predicted : noTyping\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/4.jpg',) : predicted : noTyping\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/42 copy 2.jpg',) : predicted : typing\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/42 copy.jpg',) : predicted : typing\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/42-1 copy 2.jpg',) : predicted : typing\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/42-1 copy.jpg',) : predicted : typing\n",
      "('/Users/XXX/Desktop/UsageTesting-Repo/video_data/6pm-video-signin-2/test/b/42-1.jpg',) : predicted : typing\n"
     ]
    }
   ],
   "source": [
    "# iterate over data\n",
    "\n",
    "for images, labels, paths in dataloader:\n",
    "\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    for i in range(len(images)):\n",
    "        image = to_pil(images[i])\n",
    "        index = predict_image(image)\n",
    "        print(paths , \":\", \"predicted :\",str(classes[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
